{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A \"Hello World\" Example of Machine Learning - Revisit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the Iris dataset from scikit-learn. \n",
    "\n",
    "The first column represents Sepal length, the second column represents Sepal width,  the third column represents the petal length, and the fourth column the petal width of the flower samples. The classes (type of species) are already converted to integer labels where 0=Iris-Setosa, 1=Iris-Versicolor, 2=Iris-Virginica.\n",
    "\n",
    "Here, we are using only two features: the first and fourth columns. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "import numpy as np\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "#iris.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = iris.data[:, [0, 3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Class labels: [0 1 2]\n"
    }
   ],
   "source": [
    "print('Class labels:', np.unique(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scikit-learn algorithms support multi-class classification via the One-Versus-Rest(OvR) method. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting data into 70% training and 30% test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=1, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Labels counts in y: [50 50 50]\nLabels counts in y_train: [35 35 35]\nLabels counts in y_test: [15 15 15]\n"
    }
   ],
   "source": [
    "print('Labels counts in y:', np.bincount(y))\n",
    "print('Labels counts in y_train:', np.bincount(y_train))\n",
    "print('Labels counts in y_test:', np.bincount(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standardizing the features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "sc = StandardScaler() # center the distribution around zero (mean), with a standard deviation of 1.\n",
    "sc.fit(X_train)\n",
    "X_train_std = sc.transform(X_train)\n",
    "X_test_std = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "Perceptron(alpha=0.0001, class_weight=None, early_stopping=False, eta0=0.1,\n           fit_intercept=True, max_iter=100, n_iter_no_change=5, n_jobs=None,\n           penalty=None, random_state=42, shuffle=True, tol=0.001,\n           validation_fraction=0.1, verbose=0, warm_start=False)"
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "from sklearn.linear_model import Perceptron\n",
    "\n",
    "ppn = Perceptron(max_iter=100, eta0=0.1, random_state=42)\n",
    "ppn.fit(X_train_std, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the model with the hold-out test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Misclassified samples: 10\n"
    }
   ],
   "source": [
    "y_pred = ppn.predict(X_test_std)\n",
    "print('Misclassified samples: ' + str((y_test != y_pred).sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Accuracy: 0.7777777777777778\n"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print('Accuracy: ' + str(accuracy_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([2, 2, 2])"
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "X_new = [[1.1, 0.2],[0.4, 1.9], [1.4, 0.2]] #BAD - not standardized, not accurate\n",
    "y_new = ppn.predict(X_new)\n",
    "y_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the model using cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([0.88888889, 0.76923077, 0.53846154, 0.80769231])"
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "cross = cross_val_score(ppn, X_train_std, y_train, cv=4, scoring=\"accuracy\") # four folds, produces accuracy scores\n",
    "cross"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.7510683760683761"
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "import statistics\n",
    "statistics.mean(cross)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2-features: accuracy score: array([0.88888889, 0.48148148, 0.7037037 , 0.95833333])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1: Use all four features to train the model and use cross validaton to check if the results better? Briefly explain why. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X = iris.data\n",
    "y = iris.target"
   ]
  },
  {
   "source": [
    "Splitting data into 70% training and 30% test data:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=1, stratify=y)"
   ]
  },
  {
   "source": [
    "Standardizing the features"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = StandardScaler() \n",
    "sc.fit(X_train)\n",
    "X_train_std = sc.transform(X_train)\n",
    "X_test_std = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "Perceptron(alpha=0.0001, class_weight=None, early_stopping=False, eta0=0.1,\n           fit_intercept=True, max_iter=100, n_iter_no_change=5, n_jobs=None,\n           penalty=None, random_state=42, shuffle=True, tol=0.001,\n           validation_fraction=0.1, verbose=0, warm_start=False)"
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "ppn = Perceptron(max_iter=100, eta0=0.1, random_state=42)\n",
    "ppn.fit(X_train_std, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Misclassified samples: 3\nAccuracy: 0.9333333333333333\n"
    }
   ],
   "source": [
    "y_pred = ppn.predict(X_test_std)\n",
    "print('Misclassified samples: ' + str((y_test != y_pred).sum()))\n",
    "\n",
    "print('Accuracy: ' + str(accuracy_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([0.92592593, 0.88461538, 0.84615385, 0.88461538])"
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "source": [
    "cross = cross_val_score(ppn, X_train_std, y_train, cv=4, scoring=\"accuracy\")\n",
    "cross"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.8853276353276354"
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "source": [
    "statistics.mean(cross)"
   ]
  },
  {
   "source": [
    "When you use more features, you will have a better perceptron model. When using only 2 features (columns 0 and 3), our accuracy score was 0.7777777777777778. However, with 4 features (the entire dataset) the accuracy score is 0.9333333333333333.\n",
    "\n",
    "The same concept applies to cross validation. With two features, the average cross validation score was 0.7510683760683761 ([0.88888889, 0.76923077, 0.53846154, 0.80769231]). However, when you use the entire dataset, the average cross validation score was 0.8853276353276354 ([0.92592593, 0.88461538, 0.84615385, 0.88461538]).\n",
    "\n",
    "The number of partitioning with cross validation definitely matters. You must partition the data in such a way that the samples are large enough to accurately represent the dataset as a whole. If you partition the data poorly, you will produce an accuracy score that is not representative."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2: Try with the scikit-learn stochastic gradient descent model instead of perceptron. Use all four features. Evaluate with cross-validation how does the model perform in terms of accuracy using both two features and four features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "sgd = SGDClassifier(random_state=42)"
   ]
  },
  {
   "source": [
    "Two Features:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X = iris.data[:, [0, 3]] # Only two columns\n",
    "y = iris.target"
   ]
  },
  {
   "source": [
    "Splitting data into 70% training and 30% test data:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=1, stratify=y)"
   ]
  },
  {
   "source": [
    "Standardizing the features"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = StandardScaler() \n",
    "sc.fit(X_train)\n",
    "X_train_std = sc.transform(X_train)\n",
    "X_test_std = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n              early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n              l1_ratio=0.15, learning_rate='optimal', loss='hinge',\n              max_iter=1000, n_iter_no_change=5, n_jobs=None, penalty='l2',\n              power_t=0.5, random_state=42, shuffle=True, tol=0.001,\n              validation_fraction=0.1, verbose=0, warm_start=False)"
     },
     "metadata": {},
     "execution_count": 25
    }
   ],
   "source": [
    "sgd.fit(X_train_std, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Misclassified samples: 1\nAccuracy: 0.9777777777777777\n"
    }
   ],
   "source": [
    "y_pred = sgd.predict(X_test_std)\n",
    "print('Misclassified samples: ' + str((y_test != y_pred).sum()))\n",
    "\n",
    "print('Accuracy: ' + str(accuracy_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[0.92592593 0.76923077 0.96153846 0.80769231]\n0.8660968660968661\n"
    }
   ],
   "source": [
    "cross = cross_val_score(sgd, X_train_std, y_train, cv=4, scoring=\"accuracy\")\n",
    "print(cross)\n",
    "print(statistics.mean(cross))"
   ]
  },
  {
   "source": [
    "Using two features with the stochastic gradient descent model, the produced accuracy score was 0.9777777777777777. The average of the cross validation scores was 0.8660968660968661 ([0.92592593 0.76923077 0.96153846 0.80769231])."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Four Features:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X = iris.data\n",
    "y = iris.target"
   ]
  },
  {
   "source": [
    "Splitting data into 70% training and 30% test data:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=1, stratify=y)"
   ]
  },
  {
   "source": [
    "Standardizing the data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = StandardScaler() \n",
    "sc.fit(X_train)\n",
    "X_train_std = sc.transform(X_train)\n",
    "X_test_std = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n              early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n              l1_ratio=0.15, learning_rate='optimal', loss='hinge',\n              max_iter=1000, n_iter_no_change=5, n_jobs=None, penalty='l2',\n              power_t=0.5, random_state=42, shuffle=True, tol=0.001,\n              validation_fraction=0.1, verbose=0, warm_start=False)"
     },
     "metadata": {},
     "execution_count": 31
    }
   ],
   "source": [
    "sgd.fit(X_train_std, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Misclassified samples: 5\nAccuracy: 0.8888888888888888\n"
    }
   ],
   "source": [
    "y_pred = sgd.predict(X_test_std)\n",
    "print('Misclassified samples: ' + str((y_test != y_pred).sum()))\n",
    "\n",
    "print('Accuracy: ' + str(accuracy_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[1.         0.96153846 0.84615385 0.88461538]\n0.9230769230769231\n"
    }
   ],
   "source": [
    "cross = cross_val_score(sgd, X_train_std, y_train, cv=4, scoring=\"accuracy\")\n",
    "print(cross)\n",
    "print(statistics.mean(cross))"
   ]
  },
  {
   "source": [
    "Using all features with the stochastic gradient descent model, the produced accuracy score was 0.8888888888888888. The average of the cross validation scores was 0.9230769230769231 ([1.         0.96153846 0.84615385 0.88461538])"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "With more data, the stochastic gradient descent model will jump around more before converging and will consequently produce a lower accuracy score. This concept is seen in the models above since 2 features produced an accuracy score of 0.9777777777777777 and 4 features produced an accuracy score of 0.8888888888888888."
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "Python 3.7.7 64-bit ('base': conda)",
   "display_name": "Python 3.7.7 64-bit ('base': conda)",
   "metadata": {
    "interpreter": {
     "hash": "ae047f309207100232e67de43bfc3b377c01487b136182ae2aebbd16956d2969"
    }
   }
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}